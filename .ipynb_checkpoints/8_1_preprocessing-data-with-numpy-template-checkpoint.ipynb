{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Missing Values\n",
    "- Missing values can be checked with the help of loadtxt function.\n",
    "- They can also be checked with np.isnan() function. It returns true for NaN values if there and we can sum that array up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This load function works on the files with only numeric values, by default, so if there are missing values we will come \n",
    "# to know by the error that will be produced.\n",
    "lending_co_numeric = np.loadtxt(\"./Data/Lending-company-Numeric.csv\",delimiter = ',')\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lending_co_numeric_NaN = np.loadtxt(\"./Data/Lending-company-Numeric-NAN.csv\",delimiter = ';') # Will return an error\n",
    "lending_co_numeric_NaN = np.genfromtxt(\"./Data/Lending-company-Numeric-NAN.csv\",delimiter = ';')\n",
    "lending_co_numeric_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of NaN values is 0\n",
      "Sum of NaN values is 260\n"
     ]
    }
   ],
   "source": [
    "# np.isnan() method returns an array of True or bool(1) for all the missing values. So if we add them and there are missing \n",
    "# values the sum will always be greater than 0, else the sum will be 0.\n",
    "print(f\"Sum of NaN values is {np.isnan(lending_co_numeric).sum()}\")\n",
    "print(f\"Sum of NaN values is {np.isnan(lending_co_numeric_NaN).sum()}\")\n",
    "# In the NaN file there are 260 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling of Missing Values.\n",
    "- We fill the missing values with the help up of fill_values parameter of the importing function of genfromtxt.\n",
    "- This will fill all the missing values with a single value, but this function works on all column at once, not on the individual columns, we need to workaround with usecols.\n",
    "- We fill with a value that is not present in the dataset or that doesn't alter the distribution much. Filling a 0 is not much of a sense so we will fill it with a value greater than the max of the dataset.\n",
    "- However filling the dataset with a value greater than the max for all missing values, does alter the mean of the individual columns and the filler value may act as an outlier for the column so we use another filler values for each individual columns and thus we use the np.where() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64001.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric_without_fill = np.genfromtxt(\"./Data/Lending-company-Numeric-NAN.csv\",\n",
    "                                        delimiter = ';')\n",
    "max_fill = np.nanmax(lending_co_numeric_fill)\n",
    "print(max_fill)\n",
    "lending_co_numeric_without_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250.2477700693757\n"
     ]
    }
   ],
   "source": [
    "# Mean for column before filler values.\n",
    "temp_mean = np.nanmean(lending_co_numeric_fill[:,0])\n",
    "print(temp_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substituting Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4263.28092042186\n"
     ]
    }
   ],
   "source": [
    "# Mean after filling the max value of the dataset.\n",
    "lending_co_numeric_fill = np.genfromtxt(\"./Data/Lending-company-Numeric-NAN.csv\",\n",
    "                                        delimiter = ';',\n",
    "                                        filling_values=max_fill+1)\n",
    "# Mean for column before filler values.\n",
    "temp_mean = np.nanmean(lending_co_numeric_fill[:,0])\n",
    "print(temp_mean) \n",
    "# Thus the filler value changes the  mean totally, so we need to put a value as mean of that particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250.2478427612655"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the dataset with max_fill as nan values so that it can be used in the np.where() for applying condition.\n",
    "\n",
    "# Creating temperory mean for every column \n",
    "temp_mean = np.nanmean(lending_co_numeric_without_fill,axis = 0).round(2)\n",
    "\n",
    "# Substituting the NaN values in a particular column with the mean of the column values itself.\n",
    "for i in range((lending_co_numeric_fill.shape[1])):\n",
    "    lending_co_numeric_fill[:,i] = np.where(lending_co_numeric_fill[:,i]==(max_fill+1),\n",
    "                                            temp_mean[i],\n",
    "                                            lending_co_numeric_fill[:,i])\n",
    "    \n",
    "#Checking the mean after filling each collumns own mean.\n",
    "np.mean(lending_co_numeric_fill[:,0]) # It comes inline with mean of the column, thus nature of data remains same.\n",
    "# We can also fill the values with mode, median etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 6), dtype=float64)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric_fill[(lending_co_numeric_fill[:,0])==np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "- This is a quite useful feature to be done in data manipulation, because certain functions or methods only work on specific size of arrays that requires reshaping an array.\n",
    "- In reshaping remember that the product of the dimensions need to be conserved always.\n",
    "- Remember the reshape function doesn't change the original array instead it returns a new object with the made changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric = np.loadtxt('./Data/Lending-company-Numeric.csv',delimiter=',')\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knowing the shape of the original array.\n",
    "lending_co_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the shape with reshape function.\n",
    "np.reshape(lending_co_numeric,(6,1043))\n",
    "# Doing this doesn't transpose the matrix, just it takes first 1043 values and puts it in first row, and continues this \n",
    "# operation for the next consecutive 1043 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1043)\n"
     ]
    }
   ],
   "source": [
    "# Transpose is used to get the transpose of the matrix.\n",
    "np.transpose(lending_co_numeric)\n",
    "print(np.transpose(lending_co_numeric).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "        [12277.,  2000.,    40., ...,    50.,   365.,  5350.]],\n",
       "\n",
       "       [[ 6850., 15150.,  1000., ...,  2000.,    40.,   365.],\n",
       "        [ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.]],\n",
       "\n",
       "       [[  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "        [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(lending_co_numeric,(3,2,1043)) # Creating a 3D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[[[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "            [12277.,  2000.,    40., ...,    50.,   365.,  5350.]],\n",
       "\n",
       "           [[ 6850., 15150.,  1000., ...,  2000.,    40.,   365.],\n",
       "            [ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.]],\n",
       "\n",
       "           [[  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "            [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]]]]]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(lending_co_numeric,(1,1,1,1,3,2,1043))\n",
    "# We can create any dimensional array with reshape, and sometimes we can increase dimension with adding extra ones.\n",
    "# We can know dimension by the no. of brackets at the start and end of bracket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Values\n",
    "- For removing the columns or the rows we will use the np.delete() function.\n",
    "- Using np.delete() function removes the values after they are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the database.\n",
    "lending_co_numeric = np.loadtxt(\"./Data/Lending-company-Numeric.csv\",delimiter = ',')\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   40.,   365.,  3121., ...,  4601.,  4601., 16600.])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(lending_co_numeric, 0, axis = None)\n",
    "# When the axis is none the array is treated as the flat array and entrys with the specified index are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.,   365.,  3121.,  4241., 13621.],\n",
       "       [   40.,   365.,  3061.,  4171., 15041.],\n",
       "       [   40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   40.,   365.,  4201.,  5001., 16600.],\n",
       "       [   40.,   365.,  2080.,  3320., 15600.],\n",
       "       [   40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(lending_co_numeric,0,axis = 1)\n",
    "# With this we will be deleting the 1st column of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  40., 3061., 4171.],\n",
       "       [  40., 2160., 3280.],\n",
       "       [  40., 3041., 4241.],\n",
       "       ...,\n",
       "       [  40., 4240., 5440.],\n",
       "       [  40., 4201., 5001.],\n",
       "       [  40., 2080., 3320.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(np.delete(lending_co_numeric,(0,2,5),axis = 1),(0,-1),axis = 0)\n",
    "# This will delete the given 1,3,6 columns first and then delete the rows from the edited matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Data\n",
    "- With the np.sort() function we can sort a given array. \n",
    "- The result changes with the axis that are provided as the input.\n",
    "- By default the sorting occurs in the ascending manner and to get descending order there is a workaround without a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 2, 1]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a = np.array([[1,2,3,4],[0,1,0,1],[0,1,2,1]])\n",
    "array_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(array_a) #By default the axis is -1, which is equivalent to slicing -1. This will choose the last dimension for \n",
    "# sorting which is of column of the array. So the data is sorted in each individual row.\n",
    "np.sort(array_a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(array_a, axis = 0)\n",
    "array_a.shape # Sorting doesn't change the shape of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(array_a.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 2, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [2, 1, 1, 0]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.sort(-array_a,axis = 1) # This sorts the data in descending or the decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 1, 2, 1],\n",
       "       [0, 1, 0, 1]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.sort(-array_a,axis = 0) # This sorts the array row wise in individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 2, 1]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a #Above functions doesn't do the sorting inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 1, 2]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a.sort(axis = 1) #This function does the sorting in place adn changes the dataset.\n",
    "array_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar bits can be worked out with the lending_co_numeric array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Functions\n",
    "- np.argsort() is similar to the sort function, but instead of showing the sorted values in output it shows the sorted index of the values in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7, 6, 9],\n",
       "       [0, 1, 0, 5],\n",
       "       [0, 3, 6, 1]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a = np.array([[5,7,6,9],[0,1,0,5],[0,3,6,1]])\n",
    "array_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1, 3],\n",
       "       [0, 2, 1, 3],\n",
       "       [0, 3, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(array_a,axis = 1)\n",
    "# For first row, element with 2th index in original array i.e. 6 will come to 1th index in sorted array, likewise element\n",
    "# with 1th index in original array i.e. 7 will come to 2th index in the sorted array.\n",
    "# Similar thing will happen for all the array elements per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will sort the whole array by particular columns by using conditional slicing.\n",
    "# Its like slicing one column and then making changes on the rest of columns as well.\n",
    "# We can only use the argsort not sort function cause argsort gives indices, while the sort does not.\n",
    "array_b = array_a[np.argsort(array_a[:,3],axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 6, 1],\n",
       "       [0, 1, 0, 5],\n",
       "       [5, 7, 6, 9]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7, 6, 9],\n",
       "       [0, 1, 0, 5],\n",
       "       [0, 3, 6, 1]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1, 3],\n",
       "       [0, 2, 1, 3],\n",
       "       [0, 3, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a.argsort() # This doesn't do the inplace sorting as the ndarray.sort() does.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7, 6, 9],\n",
       "       [0, 1, 0, 5],\n",
       "       [0, 3, 6, 1]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.argwhere()\n",
    "- This is also a function which returns an array of indices of the elements of the array.\n",
    "- The default condition in the block is checking whether the element is 0 or not. True is return when the element is non-zero.\n",
    "- We can also specify different condition as we like.\n",
    "- We can change the missing values in this way for an ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric_NaN = np.genfromtxt('./Data/Lending-company-Numeric-NAN.csv',delimiter = ';')\n",
    "lending_co_numeric_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lending_co_numeric_NaN).sum() # There are total 260 missing values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [   0,    1],\n",
       "       [   0,    2],\n",
       "       ...,\n",
       "       [1042,    3],\n",
       "       [1042,    4],\n",
       "       [1042,    5]], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(lending_co_numeric_NaN) # Since we have a 2D array we get those positions where we have non-Zero values.\n",
    "# There is no axis function here and this is the way how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 1042, 1042, 1042], dtype=int64),\n",
       " array([0, 1, 2, ..., 3, 4, 5], dtype=int64))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(lending_co_numeric_NaN) #This where function also returns indices where the values are non-zero just the row\n",
    "# index are given in the first array while the column index are given in the second array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7, 6, 9],\n",
       "       [0, 1, 0, 5],\n",
       "       [0, 3, 6, 1]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 1, 2, 2, 2], dtype=int64),\n",
       " array([0, 1, 2, 3, 1, 3, 1, 2, 3], dtype=int64))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 2],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can change the condition to obtain the positions in 2D array where the values are 0\n",
    "np.argwhere(array_a == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 2],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(array_a == False) # In argwhere we cant' give the value to be given in the position, like we can give in where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To alter the value at those indices...we use a for loop.\n",
    "for i in np.argwhere(array_a == False):\n",
    "    array_a[i[0],i[1]] = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7,  6,  9],\n",
       "       [23,  1, 23,  5],\n",
       "       [23,  3,  6,  1]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a # So we have replaced the 0 values from our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining np.isnan and np.argwhere to replace the NaN values in an array.\n",
    "# np.isnan() creates an array with true values in the place where there are missing values.\n",
    "# So applying np.isnan() on an array and then putting it in np.argwhere will give the positions of indices which are \n",
    "# true as per the np.isnan() function. These are those values which are missing, so by default we will get the positions \n",
    "# of those arrays which are actually missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.argwhere(np.isnan(lending_co_numeric_NaN)):\n",
    "    lending_co_numeric_NaN[i[0],i[1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking now whether there are any missing values or not.\n",
    "np.isnan(lending_co_numeric_NaN).sum() #Since sum is 0 so there are no further missing values in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling Data\n",
    "- With the help up of shuffling data we simply move the rows up and down the dataset.\n",
    "- This is ensured to have random rows in the dataset and we can choose a sample from this random data.\n",
    "- However the data in a single row doesn't gets shuffled only the rows move up and down in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric = np.loadtxt(\"./Data/Lending-Company-Numeric-Data.csv\",delimiter = ',')[:8] #Loading the starting 8 rows.\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(lending_co_numeric) # This shuffles the data in place and thus gives no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric #Executing above cell many no. of times shuffles the cell many no. of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import shuffle\n",
    "shuffle(lending_co_numeric) #After importing calling becomes easy.\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator as gen\n",
    "from numpy.random import PCG64 as pcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_RG = gen(pcg())\n",
    "array_RG.shuffle(lending_co_numeric)\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_RG = gen(pcg(seed  = 365))  # For shuffle fixing a seed also doesn't fix the output, the output still \n",
    "# keeps on changing that's the by default way how shuffle works.\n",
    "array_RG.shuffle(lending_co_numeric)\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting\n",
    "- Casting refers to changing the data type of the elements by using a astype method.\n",
    "- Astype method doesn't work in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000,    40,   365,  3041,  4241, 15321],\n",
       "       [ 2000,    40,   365,  3121,  4241, 13621],\n",
       "       [ 2000,    50,   365,  1851,  3251, 17701],\n",
       "       [ 2000,    40,   365,  3971,  4131, 15351],\n",
       "       [ 1000,    40,   365,  2160,  3280, 15340],\n",
       "       [ 2000,    40,   365,  3061,  4171, 15041],\n",
       "       [ 2000,    50,   365,  3470,  4820, 13720],\n",
       "       [ 2000,    40,   365,  3201,  4141, 14141]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric.astype(np.int32) #converting float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric.astype(np.float64) #converting back to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_numeric = lending_co_numeric.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '2000.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-267-12d2872cf816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlending_co_numeric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '2000.0'"
     ]
    }
   ],
   "source": [
    "lending_co_numeric.astype(np.int32) # We can't change str with '.' to int directly so we convert to float64 and then to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_numeric = lending_co_numeric.astype(np.float64).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000,    40,   365,  3041,  4241, 15321],\n",
       "       [ 2000,    40,   365,  3121,  4241, 13621],\n",
       "       [ 2000,    50,   365,  1851,  3251, 17701],\n",
       "       [ 2000,    40,   365,  3971,  4131, 15351],\n",
       "       [ 1000,    40,   365,  2160,  3280, 15340],\n",
       "       [ 2000,    40,   365,  3061,  4171, 15041],\n",
       "       [ 2000,    50,   365,  3470,  4820, 13720],\n",
       "       [ 2000,    40,   365,  3201,  4141, 14141]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stripping Data\n",
    "- This refers to removing extra text from strings without removing the whole string.\n",
    "- We use the np.chararray.strip() function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id_1', 'Product B', 'Location 2'],\n",
       "       ['id_2', 'Product B', 'Location 3'],\n",
       "       ['id_3', 'Product C', 'Location 5'],\n",
       "       ...,\n",
       "       ['id_413', 'Product B', 'Location 135'],\n",
       "       ['id_414', 'Product C', 'Location 200'],\n",
       "       ['id_415', 'Product A', 'Location 8']], dtype='<U12')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_TP = np.genfromtxt('./Data/Lending-Company-Total-Price.csv',\n",
    "                              delimiter = ',',\n",
    "                              dtype = str,\n",
    "                              skip_header=1,usecols=(1,2,4))\n",
    "lending_co_TP # We want to remove id, product and location from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_TP[:,0] = np.chararray.strip(lending_co_TP[:,0],\"id_\") #This method is also not inplace so we need to store it.\n",
    "lending_co_TP[:,1] = np.chararray.strip(lending_co_TP[:,1],\"Product \")\n",
    "lending_co_TP[:,2] = np.chararray.strip(lending_co_TP[:,2],\"Location \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'B', '2'],\n",
       "       ['2', 'B', '3'],\n",
       "       ['3', 'C', '5'],\n",
       "       ...,\n",
       "       ['413', 'B', '135'],\n",
       "       ['414', 'C', '200'],\n",
       "       ['415', 'A', '8']], dtype='<U12')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'B', '2'],\n",
       "       ['2', 'B', '3'],\n",
       "       ['3', 'C', '5'],\n",
       "       ...,\n",
       "       ['413', 'B', '135'],\n",
       "       ['414', 'C', '200'],\n",
       "       ['415', 'A', '8']], dtype='<U12')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we can replace the strings with integer values or the float values.\n",
    "# Can't convert like this we need to convert for the whole array at once.\n",
    "lending_co_TP[:,0] = lending_co_TP[:,0].astype(dtype = np.int32)\n",
    "lending_co_TP[:,2] = lending_co_TP[:,2].astype(dtype = np.int32)\n",
    "lending_co_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '1', '2'],\n",
       "       ['2', '1', '3'],\n",
       "       ['3', '1', '5'],\n",
       "       ...,\n",
       "       ['413', '1', '135'],\n",
       "       ['414', '1', '200'],\n",
       "       ['415', '1', '8']], dtype='<U12')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since above cell doesnt' make changes so we change the chars of product to numeric values.\n",
    "lending_co_TP[:,1] = np.where(lending_co_TP[:,1]=='A',1,lending_co_TP[:,1])\n",
    "lending_co_TP[:,1] = np.where(lending_co_TP[:,1]=='B',1,lending_co_TP[:,1])\n",
    "lending_co_TP[:,1] = np.where(lending_co_TP[:,1]=='C',1,lending_co_TP[:,1])\n",
    "lending_co_TP[:,1] = np.where(lending_co_TP[:,1]=='D',1,lending_co_TP[:,1])\n",
    "lending_co_TP[:,1] = np.where(lending_co_TP[:,1]=='E',1,lending_co_TP[:,1])\n",
    "lending_co_TP[:,1] = np.where(lending_co_TP[:,1]=='F',1,lending_co_TP[:,1])\n",
    "lending_co_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   1,   2],\n",
       "       [  2,   1,   3],\n",
       "       [  3,   1,   5],\n",
       "       ...,\n",
       "       [413,   1, 135],\n",
       "       [414,   1, 200],\n",
       "       [415,   1,   8]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_TP = lending_co_TP.astype(dtype = np.int32)\n",
    "lending_co_TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "- Stacking refers to putting one array above the other when they have similar dimensions, but it all depends what type of stacking is being done.\n",
    "- There are different functions like np.stack(),np.hstack(),np.vstack(),np.dstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000,    40,   365,  3121,  4241, 13621],\n",
       "       [ 2000,    40,   365,  3061,  4171, 15041],\n",
       "       [ 1000,    40,   365,  2160,  3280, 15340],\n",
       "       ...,\n",
       "       [ 2000,    40,   365,  4201,  5001, 16600],\n",
       "       [ 1000,    40,   365,  2080,  3320, 15600],\n",
       "       [ 2000,    40,   365,  4601,  4601, 16600]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric = np.loadtxt('./Data/Lending-company-Numeric.csv',delimiter = ',',dtype = np.int32)\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000, 2000, 1000, ..., 2000, 1000, 2000],\n",
       "       [  40,   40,   40, ...,   40,   40,   40]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((lending_co_numeric[:,0],lending_co_numeric[:,1]),axis = 0)\n",
    "#lending_co_numeric[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  40, 2000],\n",
       "       [  40, 2000],\n",
       "       [  40, 1000],\n",
       "       ...,\n",
       "       [  40, 2000],\n",
       "       [  40, 1000],\n",
       "       [  40, 2000]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((lending_co_numeric[:,1],lending_co_numeric[:,0]),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-319-ee42e8540815>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlending_co_numeric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlending_co_numeric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# This gives error as the second array have different shape than the first one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# We can do multiple stacking by specifying each array individually.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\Softs\\Anaconda\\envs\\myenv\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all input arrays must have the same shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "np.stack((lending_co_numeric[:,1],lending_co_numeric[:,:2]),axis = 0) \n",
    "# This gives error as the second array have different shape than the first one.\n",
    "# We can do multiple stacking by specifying each array individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  40,   40,   40, ...,   40,   40,   40],\n",
       "       [2000, 2000, 1000, ..., 2000, 1000, 2000]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((lending_co_numeric[:,1],lending_co_numeric[:,0]))\n",
    "# Here we are stacking the arrays one below the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000,   40],\n",
       "       [2000,   40],\n",
       "       [1000,   40],\n",
       "       ...,\n",
       "       [2000,   40],\n",
       "       [1000,   40],\n",
       "       [2000,   40]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((lending_co_numeric[:,:1],lending_co_numeric[:,1:2]))\n",
    "# we are simply putting the arrays side by side so it became like concatination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 6, 8, 5],\n",
       "       [1, 5, 2, 3]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_a = np.array([[1,2,3,4],[0,6,8,5],[1,5,2,3]])\n",
    "array_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1],\n",
       "        [2, 5],\n",
       "        [3, 2],\n",
       "        [4, 3]]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((array_a[0:1,:],array_a[2:3,:]),axis = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0, 6, 8, 5])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((array_a[0,:],array_a[1,:])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 5, 2, 3]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((array_a[0:1,:],array_a[2:3,:])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]],\n",
       "\n",
       "       [[0, 1, 2, 0],\n",
       "        [2, 1, 3, 4]]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_b = np.array([[[1,2,3,4],[5,6,7,8]],[[0,1,2,0],[2,1,3,4]]])\n",
    "array_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 8],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(array_b,axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Left do it by watching the videos for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_numeric_nan = np.genfromtxt('./Data/Lending-Company-Numeric-Data-NAN.csv',delimiter = ';')\n",
    "lending_co_numeric_nan\n",
    "\n",
    "# Filling with max_fill for nan values.\n",
    "max_fill = np.nanmax(lending_co_numeric_nan)+1\n",
    "lending_co_numeric_fill = np.genfromtxt('./Data/Lending-Company-Numeric-Data-NAN.csv',\n",
    "                                        delimiter = ';',\n",
    "                                        filling_values=max_fill)\n",
    "lending_co_numeric_fill\n",
    "\n",
    "# Filling the max fill with columns individual mean.\n",
    "temp_mean = np.nanmean(lending_co_numeric_nan,axis = 0).round(2)\n",
    "\n",
    "for i in range(lending_co_numeric_fill.shape[1]):\n",
    "    lending_co_numeric_fill[:,i] = np.where(lending_co_numeric_fill[:,i]==max_fill,temp_mean[0],lending_co_numeric_fill[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_numeric = np.loadtxt('./Data/Lending-company-Numeric.csv',delimiter = ',')\n",
    "lending_co_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2870., -2550., -2450., ..., 52751., 54625., 64001.])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lending_co_numeric) # This finds the unique values in the whole array and also sorts them in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 35.,  40.,  50., 125., 165.]),\n",
       " array([327,   0,   4,  19,  27], dtype=int64),\n",
       " array([  4, 567, 451,  19,   2], dtype=int64))"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lending_co_numeric[:,1],return_counts = True, return_index = True) \n",
    "# This gives the unique values in the 2nd collumn.\n",
    "# Returning count actually returns how many times the value has been appeared.\n",
    "# Returning index actually returns the index, when the first time the value appeared.\n",
    "# By default returning index array comes second, this is seen by 0 value which can be only for index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
