{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the tasks that need to be done by a data analyst in preprocessing the data.\n",
    "- 1) The analyst is provided with the necessary changes required in the dataset and also the dataset.\n",
    "- In this preprocessing following bits need to be done:\n",
    "    + Convert the data in the quantified form i.e. every value is numeric, for this we make categories and assign numbers or have positive, negative connotations or simple 0 and 1 as the values.\n",
    "    + There is a need to convert USD values to EUR currency.\n",
    "    + The data has to be clean and not possessing outliers and missing values for the model to run.\n",
    "    + Filling values is done keeping in mind we are creating a CRM: Credit risk model for a bank so that we can find the defaulters on their details and not provide give them loans.\n",
    "    + Thus the values are filled keeping in mind the creditworthiness of a customer.\n",
    "        1) We need to be extreme risk-averse and distrustful.\n",
    "        2) Missing information suggests foul play.\n",
    "        3) If the information isn't available, we'll just assume the worst.\n",
    "- 2) Its always a good idea to have the alterations done on paper before being done on data, this will save a lot of time in the long run.\n",
    "- 3) The following tasks are performed on the data on a brief:\n",
    "    + Importing and Examining Data.\n",
    "    + Splitting the data to strings and numeric values and headers. This allows easy handling of the data.\n",
    "    + Manipulating the data, by removing missing values, converting the strings to the equivalent numeric values on the base of the above instructions.\n",
    "    + Creating checkpoints in the midway when major tasks like manipulating strings is done, then numeric cols is done etc.\n",
    "    + Finally we may sort the dataset and combine all the splitted data into a single variable, ready to be imported into the data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used in the process and the use of the functions.\n",
    "- np.loadtxt(),np.genfromtxt()\n",
    "    + To know whether file has nan values or not and also importing the data.\n",
    "- np.isnan()\n",
    "    + To know whether there are nan_values in data or not with sum attribute.\n",
    "- np.unique()\n",
    "    + Pretty handy to know unique values in data, also their count and the index at which they appeared first.\n",
    "    + Able to help in analytics like assigning mean or min or max or mode is useful for an array.\n",
    "- np.isin()\n",
    "    + Checks if certain value lies in a certain array.\n",
    "- np.nanmean(),np.nanmin(),np.nanmax()\n",
    "    + Gives the basic stats values.\n",
    "- np.argwhere()\n",
    "    + Gives the indices of elements satisfying a given condition.\n",
    "- np.argsort()\n",
    "    + Gives the indices where the element will belong after sorting array.\n",
    "- np.where()\n",
    "    + Helps to replace the values which are equal to certain specific values in a column.\n",
    "- np.savez()\n",
    "    + This will save the data in a np's archive format in which .npy files are stored which can be accessed faster.\n",
    "- np.savetxt()\n",
    "    + Helps to save the file in a csv format or txt format with a given fmt and delimiters.\n",
    "- ndarray.chararray.strip()\n",
    "    + Used to strip the strings from a common unnecessary part.\n",
    "- np.reshape()\n",
    "    + Used to reshape arrays so they are suitable for stacking or concatenating.\n",
    "- np.vstack()\n",
    "    + Used to stack vertically on top of each other.\n",
    "- np.hstack()\n",
    "    + Used to stack the arrays horizontally side by side.\n",
    "- np.concatenate()\n",
    "    + Used to concatenate the strings side by side.\n",
    "- np.array_equal()\n",
    "    + Used as validity testing whether 2 arrays are equal or not without comparing each entry by viewing by self or without looping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True, linewidth = 100, precision = 2)\n",
    "# Supress means supressing the scientific notation.\n",
    "# Linewidth refers to the no. of characters to be seen in one line.\n",
    "# Precision refers to the precision of the float numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,         nan,         nan],\n",
       "       [48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw_data_np = np.loadtxt('./Data/loan-data.csv',delimiter = ',') This doesn't work so we have missing values.\n",
    "raw_data_np = np.genfromtxt('./Data/loan-data.csv',delimiter = ';',autostrip = True)\n",
    "raw_data_np\n",
    "# Looking at dataset we are not sure whether NaN values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Incomplete Data\n",
    "- Here we see the no. of missing values. \n",
    "- Further to fill it we try to create means with raw data to prevent outlier making.\n",
    "- We also get min and max arrays for every columns just in case to replace the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88019\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(raw_data_np).sum()) #So many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-256-dcbfdd4b8503>:2: RuntimeWarning: Mean of empty slice\n",
      "  temporary_mean = np.nanmean(raw_data_np,axis = 0) #We are finding mean for every single column.\n"
     ]
    }
   ],
   "source": [
    "temporary_fill = np.nanmax(raw_data_np)+1\n",
    "temporary_mean = np.nanmean(raw_data_np,axis = 0) #We are finding mean for every single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observing the mean data.\n",
    "temporary_mean \n",
    "# With this all the columns where mean is nan are the columns filled with strings only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-258-434f321d2c98>:2: RuntimeWarning: All-NaN slice encountered\n",
      "  temporary_stats = np.array([np.nanmin(raw_data_np, axis = 0),\n",
      "<ipython-input-258-434f321d2c98>:4: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(raw_data_np, axis = 0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling all the min, max and mean in an array.\n",
    "temporary_stats = np.array([np.nanmin(raw_data_np, axis = 0),\n",
    "                          temporary_mean,\n",
    "                          np.nanmax(raw_data_np, axis = 0)]) \n",
    "temporary_stats # Each 2d array is in same order as specified, above so mean comes in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset\n",
    "- We usually split the numeric and string columns to separate arrays so that we can work on them easily.\n",
    "- Likewise we keep the data and the headers separate so that we can work on data more efficiently and when the work is done simply we will stack the data as we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  7 13]\n",
      "[ 1  3  5  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "#### Knowing the columns where the columns are strings.\n",
    "string_columns = np.argwhere(np.isnan(temporary_mean)).squeeze(axis = 1)\n",
    "numeric_columns = np.argwhere(np.isnan(temporary_mean)!=True).squeeze(axis = 1)\n",
    "print(numeric_columns)\n",
    "print(string_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the particular columns in different arrays using genfromtxt, cause we can alter a dtype there easily.\n",
    "strings_loan_data = np.genfromtxt('./Data/loan-data.csv',\n",
    "                                  delimiter = ';',\n",
    "                                  dtype = str,\n",
    "                                  skip_header = 1,\n",
    "                                  usecols = string_columns,\n",
    "                                  autostrip = True) #Autostrip is very useful, while manipulating strings it becomes easy\n",
    "# as the whitespaces are stripped.\n",
    "strings_loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the numeric data and also filling the missing values.\n",
    "numeric_loan_data = np.genfromtxt('./Data/loan-data.csv',\n",
    "                                  delimiter = ';',\n",
    "                                  usecols = numeric_columns,\n",
    "                                  skip_header = 1,\n",
    "                                  filling_values=temporary_fill)\n",
    "numeric_loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Names of the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_header = np.genfromtxt('./Data/loan-data.csv',\n",
    "                                  delimiter = ';',\n",
    "                                  skip_footer = raw_data_np.shape[0]-1,\n",
    "                                  filling_values=temporary_fill, \n",
    "                            dtype = str,\n",
    "                            autostrip= True)\n",
    "full_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header = full_header[string_columns]\n",
    "numeric_header = full_header[numeric_columns]\n",
    "\n",
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Checkpoints\n",
    "- Creating a function that will help create the checkpoints of data so that we don't loose out on the processing that has happened until a certain point.\n",
    "- See how the function is structured, we are asking minimal bits as parameters, and the asking is intuitive and as per the needs of the savez function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header = checkpoint_header, data = checkpoint_data)\n",
    "    checkpoint_variable = np.load(file_name + \".npz\")\n",
    "    return(checkpoint_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_test_strings = checkpoint('checkpoint-test-strings',strings_header,strings_loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_test_strings['header']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_test_strings['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_test_numeric = checkpoint('checkpoint-test-numeric',numeric_header,numeric_loan_data)\n",
    "checkpoint_test_numeric['header']\n",
    "checkpoint_test_numeric['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating String Columns\n",
    "- Here we start to work only with the strings collumns at first.\n",
    "- Always have a preplan which column needs what alteration and then work on the columns one by one i.e. pretty efficient, needs less thought and is great.\n",
    "- We are using np.unique() for knowing which values are present in the whole column, without having to look at each entry.\n",
    "- Also while working we remove NaN values as per the instructions given by the team.\n",
    "- Remember ask the specific needs to the team to give the best output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_header[0] = 'issue_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_loan_data = checkpoint_test_strings['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue Date\n",
    "- We will convert the Months to numeric months so that handling of the months becomes a bit easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,0]) # Unique does sort the data but its alphabetically being strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_loan_data[:,0] = np.chararray.strip(strings_loan_data[:,0],chars = '-15') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['May', '', 'Sep', ..., 'Jun', 'Apr', 'Dec'], dtype='<U69')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this to assign the numeric values instead of strings, but they stay in form of strings.\n",
    "for i in range(13):\n",
    "        strings_loan_data[:,0] = np.where(strings_loan_data[:,0] == months[i],\n",
    "                                          i,\n",
    "                                          strings_loan_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,0]) # Strings are sorted by their ASCII values only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Status\n",
    "- Here we convert the user to a defaulter or a non-defaulter on the base of the loan-status.\n",
    "- Finally we assign 0 to defaulter and 1 to the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'Current', 'Current', ..., 'Current', 'Current', 'Current'], dtype='<U69')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "       'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(strings_loan_data[:,1]).size)\n",
    "np.unique(strings_loan_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we assign the loan status as good or bad, on basis of will the loan be repaid or not.\n",
    "good_status = ['Current','Fully Paid','Issued','In Grace Period','Late (16-30 days)']\n",
    "bad_status = ['Charged Off','Default','Late (31-120 days)','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data[:,1] = np.where(np.isin(strings_loan_data[:,1],good_status),1,0)\n",
    "np.unique(strings_loan_data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term\n",
    "- Here we see the time in which the loan is paid by the client.\n",
    "- If its 60 months, then its a defaulter, while 36 months is taken to be a good value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data[:,2] = np.chararray.strip(strings_loan_data[:,2],\" months\")\n",
    "strings_loan_data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_header[2]='term_months' #To make more sense of the the unit of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are changing the missing values to 60 to consider the worst case scenario.\n",
    "# We are not converting this to a binary dummy variable as we did for loan_status as nothing is given in instructions, \n",
    "# in real life, however we do consult with team about the significance of the variables.\n",
    "strings_loan_data[:,2] = np.where(strings_loan_data[:,2]=='',\n",
    "                                  '60',\n",
    "                                  strings_loan_data[:,2])\n",
    "np.unique(strings_loan_data[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade and Subgrade\n",
    "- Here we operate on columns and see which are redundant ones.\n",
    "- However before removing redundant columns we make use of it to fill any missing values if possible and then remove it fully.\n",
    "- We finally assign numeric values to the strings as per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,4]) \n",
    "#Since we have subgrade column and the grades can be derived from sub-grade, grades column is redundant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But before removing grade, we will fill the subgrades missing values.\n",
    "# If for a row, there is no value for subgrade and there is a grade so we assign the string of grade+5 to it, where \n",
    "# the grade is taken from the grade column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling Sub Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(strings_loan_data[:,3])[1:]:\n",
    "    strings_loan_data[:,4] = np.where((strings_loan_data[:,4] == '') & (strings_loan_data[:,3] == i),\n",
    "                                      i + '5',\n",
    "                                      strings_loan_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "        'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "        'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267,\n",
       "        250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,4],return_counts = True) # So after substitution we stil have 9 empty rows.\n",
    "# Now these rows don't have grade and neither the subgrade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will assign such empty values as another subgrade i.e. H5\n",
    "strings_loan_data[:,4] = np.where(strings_loan_data[:,4]=='','H5',strings_loan_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "        'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "        'G1', 'G2', 'G3', 'G4', 'G5', 'H5'], dtype='<U69'),\n",
       " array([285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250,\n",
       "        255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5,   9],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,4],return_counts = True) #Now we don't have any missing values in the subgrade.\n",
    "# After this we will remove the grade column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strings_loan_data = np.delete(strings_loan_data,3,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_header = np.delete(strings_header,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "       'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "       'G1', 'G2', 'G3', 'G4', 'G5', 'H5'], dtype='<U69')"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,3]) # We get the sub grades column only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Sub Grade\n",
    "- Here we assign numeric strings to subgrades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(np.unique(strings_loan_data[:,3]))                         \n",
    "values = list(range(1, np.unique(strings_loan_data[:,3]).shape[0] + 1)) \n",
    "dict_sub_grade = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H5': 36}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(strings_loan_data[:,3]):\n",
    "        strings_loan_data[:,3] = np.where(strings_loan_data[:,3] == i, \n",
    "                                          dict_sub_grade[i],\n",
    "                                          strings_loan_data[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Status\n",
    "- Verification status needs to be processed similarly as the loan_status and we need to categorize it into defaulters and non-defaulters.\n",
    "- We will assign 1 to those who have a financial backing and 0 to those who don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will assign Not Verified, '' values to be 0, and rest as 1 in string format.\n",
    "strings_loan_data[:,4] = np.where(((strings_loan_data[:,4] == 'Not Verified')|(strings_loan_data[:,4] == '')),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL\n",
    "- In URL we actually strip the values to keep only the important part in URL which is unique to each entry.\n",
    "- Further on analysis if we find that URL is identical to ID we remove URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=12606806',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=13026045',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=1312426', ...,\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=8138291',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=8214572',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=849994'], dtype='<U69')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_loan_data[:,5] = np.chararray.strip(strings_loan_data[:,5],'https://www.lendingclub.com/browse/loanDetail.action?loan_id=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since this data is similar to id, just in string format we will remove this url column.\n",
    "#But before that lets check are all the values same.\n",
    "np.array_equal(strings_loan_data[:,5].astype(np.int32),numeric_loan_data[:,0].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We remove the Urls column from the string headers and the data array.\n",
    "#strings_header = np.delete(strings_header,5)\n",
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data = np.delete(strings_loan_data,5,axis = 1)\n",
    "strings_loan_data[:,5] # We don't get urls as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_header = np.delete(strings_header,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Address\n",
    "- Here we change the address to a more grouped one, i.e. according to regions and then number the regions.\n",
    "- The state addresses are made on a baseline, here the baseline is the state IOWA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_header[5] = 'state_address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,5]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ',\n",
       "        'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY',\n",
       "        'KS', 'OK', 'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK',\n",
       "        'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "         216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "          84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "          25,   24,   17,   16,   10], dtype=int64))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_names,state_count = np.unique(strings_loan_data[:,5],return_counts = True)\n",
    "#We want to see the results in descending order to see which state has generally more accounts in the bank.\n",
    "\n",
    "states_count_sorted = np.argsort(-state_count) # This will give indices for max to min values \n",
    "# of state count in descending order.\n",
    "state_names[states_count_sorted],state_count[states_count_sorted]\n",
    "\n",
    "# With this we are able to observe that more states have missing values.\n",
    "# So we have too little data for too many variables so we will generalize the data as per regions and we will \n",
    "# assign 0 to the missing values, so that they are not able to influence the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data[:,5]= np.where(strings_loan_data[:,5]=='',\n",
    "                                 0,\n",
    "                                 strings_loan_data[:,5])\n",
    "strings_loan_data[:,5]\n",
    "# After this we assign region to the states and then numeric strings to the regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_west = np.array(['WA', 'OR','CA','NV','ID','MT', 'WY','UT','CO', 'AZ','NM','HI','AK'])\n",
    "states_south = np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "states_midwest = np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])\n",
    "states_east = np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_loan_data[:,5] = np.where(np.isin(strings_loan_data[:,5],states_west),1,strings_loan_data[:,5])\n",
    "strings_loan_data[:,5] = np.where(np.isin(strings_loan_data[:,5],states_south),2,strings_loan_data[:,5])\n",
    "strings_loan_data[:,5] = np.where(np.isin(strings_loan_data[:,5],states_midwest),3,strings_loan_data[:,5])\n",
    "strings_loan_data[:,5] = np.where(np.isin(strings_loan_data[:,5],states_east),4,strings_loan_data[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U69')"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strings_loan_data[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Numbers\n",
    "- Finally after converting each string data to a general numeric value we need to convert it to numeric value.\n",
    "- On a brief, we have converted the following:\n",
    "    + Issue_date to simple Months with numeric values.\n",
    "    + Loan_Status to simple 0 and 1.\n",
    "    + Term_Months to simple 0 and 1.\n",
    "    + Sub_grade to values in 1 to 36.\n",
    "    + Verification_status to 0 and 1.\n",
    "    + State_address to 1 to 4.\n",
    "- Further now we will convert the strings to numbers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', '1'],\n",
       "       ['0', '1', '36', '5', '1', '4'],\n",
       "       ['9', '1', '36', '10', '1', '4'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', '1'],\n",
       "       ['4', '1', '36', '17', '1', '3'],\n",
       "       ['12', '1', '36', '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_loan_data = strings_loan_data.astype(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 1: Strings\n",
    "- Once we are done with preprocessing the strings part we will create a checkpoint and store the strings data separately in a nypz file with its headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_strings = checkpoint('checkpoint_strings',strings_header,strings_loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_strings['header']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_strings['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(strings_loan_data,checkpoint_strings['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Numeric Columns\n",
    "- Now we have all the columns in the numeric form, however we need to modify the numeric columns a bit which are completely numeric i.e. they were the original numbers at the start.\n",
    "- We will replace the filler_values assigned to NaNs with the min for certain columns and the max for the rest columns while with mean for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header\n",
    "# Here we want to assign the worst_case values so we assign max to all the columns accept the funded amount.\n",
    "# With the funded amount being least its the worst_case, while assigning max to rest is the worst_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(numeric_loan_data).sum() # The sum is 0 because we replaced the filler values with the max of the whole array.\n",
    "# Thus we now need to substitute the filler values with min and max values for the specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporary_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitute \"Filler\" Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just check is there any temporary_fill in the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(numeric_loan_data[:,0],temporary_fill).sum() #Returns true to those position where temporary_fill is present.\n",
    "# Since output is 0 there are no missing values in ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporary_stats #Here first row is for min, second is for mean and 3rd is for max.\n",
    "# We see nan values cause temporary_stats was formed with raw_dataset. \n",
    "# So we will use the column numeric which has the column numbers for numeric data in the raw dataset itself.\n",
    "# Being for raw data the column numeric works perfectly.\n",
    "temporary_stats[:,numeric_columns]\n",
    "\n",
    "#Now we need to assign element [0,2] to missing values in funded_amt column and rest from 3rd row to remaining columns\n",
    "# except id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funded Amount\n",
    "- Assigning the min from the temporary_stats to the numeric_loan_data 3rd column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19'),\n",
       " array([ 0,  2,  4,  6,  7, 13], dtype=int64))"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header,numeric_columns # We will use numeric_column[2] for funded amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data[:,2] = np.where(numeric_loan_data[:,2] == temporary_fill, \n",
    "                                  temporary_stats[0, numeric_columns[2]],\n",
    "                                  numeric_loan_data[:,2])\n",
    "numeric_loan_data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(numeric_loan_data[:,2],temporary_fill).sum() # So no temporary fill hence further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loaned Amount, Interest Rate, Total Payment, Installment\n",
    "- Assigning the max from the temporary_stats to the numeric_loan_datas numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,3,4,5]:\n",
    "    numeric_loan_data[:,i] = np.where(numeric_loan_data[:,i]==temporary_fill,\n",
    "                                      temporary_stats[2,numeric_columns[i]],\n",
    "                                      numeric_loan_data[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(numeric_loan_data,temporary_fill).sum() # Thus we have removed the temporaryfill values from the whole numeric array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currency Change\n",
    "- Here we convert the USD to EUR, however to keep dataset a bit consistent we have both the currencies in the dataset and we keep altering the headers too as we have been doing along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EUR_USD = np.genfromtxt('./Data/EUR-USD.csv',delimiter = ',',autostrip = 1,dtype = str)\n",
    "EUR_USD\n",
    "# We only need the closing conversion rates for each entry, thus we only will keep close columns.\n",
    "EUR_USD = np.genfromtxt('./Data/EUR-USD.csv',delimiter = ',',autostrip = 1,usecols = 3,skip_header = 1)\n",
    "EUR_USD.shape # We have exchange rates for every month.\n",
    "# This will help to put exchange rates as per issue_dates month numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5,  1, 36, 13,  1,  1],\n",
       "        [ 0,  1, 36,  5,  1,  4],\n",
       "        [ 9,  1, 36, 10,  1,  4],\n",
       "        ...,\n",
       "        [ 6,  1, 36,  5,  1,  1],\n",
       "        [ 4,  1, 36, 17,  1,  3],\n",
       "        [12,  1, 36,  4,  0,  3]]),\n",
       " array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "        'state_address'], dtype='<U19'))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_loan_data,strings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09]), (10000,))"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rate = strings_loan_data[:,0]\n",
    "for i in range(1,13):\n",
    "    exchange_rate = np.where(exchange_rate == i,\n",
    "                             EUR_USD[i-1],\n",
    "                             exchange_rate)    \n",
    "\n",
    "# Since we have months from 1 to 12 itself, there are missing values assigned as value 0 in the issue date, thus \n",
    "# we assign, missing values with the mean exchange rate.\n",
    "exchange_rate = np.where(exchange_rate == 0,\n",
    "                        np.mean(EUR_USD),\n",
    "                        exchange_rate)\n",
    "exchange_rate,exchange_rate.shape\n",
    "#Now we need to put this exchnage rate as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate = np.reshape(exchange_rate,(10000,1)) #This will make the array 2D and thus able to hstack with the strings_loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_loan_data = np.hstack((numeric_loan_data,exchange_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addding exchange rate to column name.\n",
    "numeric_header = np.concatenate((numeric_header,np.array(['exchange_rate'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From USD to EUR\n",
    "- Here we want to convert the USD amounts stored in loan_amnt, funded_amnt, installment, total_pymnt to Euros.\n",
    "- We know how much 1 euros means in dollars by exchange rate, so we will divide the amounts by the exchange rates itself.\n",
    "- We will create new columns with Euro values and further stack them in our numeric_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35000.  , 35000.  ,  1184.86,  9452.96],\n",
       "       [30000.  , 30000.  ,   938.57,  4679.7 ],\n",
       "       [15000.  , 15000.  ,   494.86,  1969.83],\n",
       "       ...,\n",
       "       [10000.  , 10000.  ,  1372.97,  2185.64],\n",
       "       [35000.  , 10000.  ,   354.3 ,  3199.4 ],\n",
       "       [10000.  , 10000.  ,   309.97,   301.9 ]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dollar = [1,2,4,5]\n",
    "numeric_loan_data[:,columns_dollar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this code we actually divide every dollar columns with the exchange rate and store \n",
    "# each columns individually in the original array.\n",
    "for i in columns_dollar:\n",
    "    numeric_loan_data = np.hstack((numeric_loan_data, np.reshape(numeric_loan_data[:,i] / numeric_loan_data[:,6], (10000,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[48010226.  ,    35000.  ,    35000.  , ...,    31933.3 ,     1081.04,     8624.69],\n",
       "        [57693261.  ,    30000.  ,    30000.  , ...,    27132.46,      848.86,     4232.39],\n",
       "        [59432726.  ,    15000.  ,    15000.  , ...,    13326.3 ,      439.64,     1750.04],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,    10000.  , ...,     8910.3 ,     1223.36,     1947.47],\n",
       "        [46154151.  ,    35000.  ,    10000.  , ...,     8997.4 ,      318.78,     2878.63],\n",
       "        [66055249.  ,    10000.  ,    10000.  , ...,     9145.8 ,      283.49,      276.11]]),\n",
       " (10000, 11))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data,numeric_loan_data.shape # First we had only 7 columns now we added 4 more so we have 11 now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_additional = np.array([column_name + '_EUR' for column_name in numeric_header[columns_dollar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U15')"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_header = np.concatenate((numeric_header,header_additional))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate',\n",
       "       'loan_amnt_EUR', 'funded_amnt_EUR', 'installment_EUR', 'total_pymnt_EUR'], dtype='<U19')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_index_order = [0,1,7,2,8,3,4,9,5,10,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_header = numeric_header[columns_index_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'loan_amnt_EUR', 'funded_amnt', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment', 'installment_EUR', 'total_pymnt', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_loan_data = numeric_loan_data[:,columns_index_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rate\n",
    "- We are just getting its values in the range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'loan_amnt_EUR', 'funded_amnt', 'funded_amnt_EUR', 'int_rate',\n",
       "       'installment', 'installment_EUR', 'total_pymnt', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.33, 28.99, 28.99, ..., 28.99, 16.55, 28.99])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data[:,5] #These are the interest rates and they are required in 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_loan_data[:,5] = numeric_loan_data[:,5]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.29, 0.29, ..., 0.29, 0.17, 0.29])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_loan_data[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 2: Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_numeric = checkpoint('checkpoint-numeric',numeric_header,numeric_loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt', 'loan_amnt_EUR', 'funded_amnt', 'funded_amnt_EUR', 'int_rate',\n",
       "        'installment', 'installment_EUR', 'total_pymnt', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "       dtype='<U19'),\n",
       " array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,     8624.69,        1.1 ],\n",
       "        [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,     4232.39,        1.11],\n",
       "        [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,     1750.04,        1.13],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,     1947.47,        1.12],\n",
       "        [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,     2878.63,        1.11],\n",
       "        [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,      276.11,        1.09]]))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_numeric['header'], checkpoint_numeric['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(checkpoint_numeric['data'],numeric_loan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the \"Complete\" Dataset\n",
    "- Finally we will be creating a single dataset from the numeric and string arrays which we have found out above.\n",
    "- We are using the checkpoints so even if the data is changed its intact in our checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "        'state_address'], dtype='<U19'),\n",
       " array(['id', 'loan_amnt', 'loan_amnt_EUR', 'funded_amnt', 'funded_amnt_EUR', 'int_rate',\n",
       "        'installment', 'installment_EUR', 'total_pymnt', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "       dtype='<U19'))"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_strings['header'],checkpoint_numeric['header']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 6), (10000, 11))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_strings['data'].shape,checkpoint_numeric['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5.  ,    1.  ,   36.  , ..., 9452.96, 8624.69,    1.1 ],\n",
       "       [   0.  ,    1.  ,   36.  , ..., 4679.7 , 4232.39,    1.11],\n",
       "       [   9.  ,    1.  ,   36.  , ..., 1969.83, 1750.04,    1.13],\n",
       "       ...,\n",
       "       [   6.  ,    1.  ,   36.  , ..., 2185.64, 1947.47,    1.12],\n",
       "       [   4.  ,    1.  ,   36.  , ..., 3199.4 , 2878.63,    1.11],\n",
       "       [  12.  ,    1.  ,   36.  , ...,  301.9 ,  276.11,    1.09]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the no. of rows in the dataset are equal we will stack them side by side.\n",
    "# We are keeping the string data first.\n",
    "loan_data = np.hstack((checkpoint_strings['data'],checkpoint_numeric['data']))\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking are there any null values in the final dataset.\n",
    "np.isnan(loan_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the headers too.\n",
    "header_full = np.hstack((strings_header, numeric_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_full[0],header_full[6] = header_full[6],header_full[0] # Bringing the id to the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data[:,0],loan_data[:,6] = loan_data[:,6],loan_data[:,0] #Bringing ids to the start in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[48010226.  ,        1.  ,       36.  , ...,     9452.96,     8624.69,        1.1 ],\n",
       "        [57693261.  ,        1.  ,       36.  , ...,     4679.7 ,     4232.39,        1.11],\n",
       "        [59432726.  ,        1.  ,       36.  , ...,     1969.83,     1750.04,        1.13],\n",
       "        ...,\n",
       "        [50415990.  ,        1.  ,       36.  , ...,     2185.64,     1947.47,        1.12],\n",
       "        [46154151.  ,        1.  ,       36.  , ...,     3199.4 ,     2878.63,        1.11],\n",
       "        [66055249.  ,        1.  ,       36.  , ...,      301.9 ,      276.11,        1.09]]),\n",
       " array(['id', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'state_address',\n",
       "        'issue_date', 'loan_amnt', 'loan_amnt_EUR', 'funded_amnt', 'funded_amnt_EUR', 'int_rate',\n",
       "        'installment', 'installment_EUR', 'total_pymnt', 'total_pymnt_EUR', 'exchange_rate'],\n",
       "       dtype='<U19'))"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data,header_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the New Dataset\n",
    "- We will sort the data as per the id.\n",
    "- However with argsort as we get the index where each element needs to belong to we will apply it to each column, so this will sort whole array by id's thus keeping the data for every row intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = loan_data[np.argsort(loan_data[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,        1.  ,       36.  , ...,     1072.82,      974.5 ,        1.1 ],\n",
       "       [  575239.  ,        1.  ,       60.  , ...,      959.75,      871.79,        1.1 ],\n",
       "       [  707689.  ,        1.  ,       36.  , ...,     3726.25,     3325.42,        1.12],\n",
       "       ...,\n",
       "       [68614880.  ,        1.  ,       36.  , ...,        0.  ,        0.  ,        1.09],\n",
       "       [68615915.  ,        1.  ,       36.  , ...,        0.  ,        0.  ,        1.09],\n",
       "       [68616519.  ,        1.  ,       36.  , ...,        0.  ,        0.  ,        1.09]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999], dtype=int64)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating whether the data is sorted or not.\n",
    "np.argsort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the New Dataset\n",
    "- Finally after sorting as per the id's we will attach the headers with v stack and save the data in a text file.\n",
    "- We can view it after saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = np.vstack((header_full,loan_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_status', 'term_months', ..., 'total_pymnt', 'total_pymnt_EUR',\n",
       "        'exchange_rate'],\n",
       "       ['373332.0', '1.0', '36.0', ..., '1072.82', '974.4960808923015', '1.100897192955017'],\n",
       "       ['575239.0', '1.0', '60.0', ..., '959.75', '871.788942820218', '1.100897192955017'],\n",
       "       ...,\n",
       "       ['68614880.0', '1.0', '36.0', ..., '0.0', '0.0', '1.093398094177246'],\n",
       "       ['68615915.0', '1.0', '36.0', ..., '0.0', '0.0', '1.093398094177246'],\n",
       "       ['68616519.0', '1.0', '36.0', ..., '0.0', '0.0', '1.093398094177246']], dtype='<U32')"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data #The data came in strings because vstack converts it to the datatype \n",
    "# that can store the data and also with least space. Here thus we have dtype = unicode in 32 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('loan_data_preprocessed_by_me.csv',\n",
    "           loan_data,\n",
    "           fmt = '%s',\n",
    "           delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_status', 'term_months', ..., 'total_pymnt', 'total_pymnt_EUR',\n",
       "        'exchange_rate'],\n",
       "       ['373332.0', '1.0', '36.0', ..., '1072.82', '974.4960808923015', '1.100897192955017'],\n",
       "       ['575239.0', '1.0', '60.0', ..., '959.75', '871.788942820218', '1.100897192955017'],\n",
       "       ...,\n",
       "       ['68614880.0', '1.0', '36.0', ..., '0.0', '0.0', '1.093398094177246'],\n",
       "       ['68615915.0', '1.0', '36.0', ..., '0.0', '0.0', '1.093398094177246'],\n",
       "       ['68616519.0', '1.0', '36.0', ..., '0.0', '0.0', '1.093398094177246']], dtype='<U19')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating that everything is great.\n",
    "loan_data_check = np.loadtxt('loan_data_preprocessed_by_me.csv',delimiter = ',',dtype = str)\n",
    "loan_data_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(loan_data,loan_data_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally the data is fully preprocessed, doesn't have any null values, and dataset is ready to be used in the model.\n",
    "# Good luck Analytics team with the further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
